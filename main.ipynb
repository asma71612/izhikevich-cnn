{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgw9zEoGY2mc"
      },
      "source": [
        "# Implement a Convolutional Spiking Neural Network with Izhikevich neuron model and STDP/R-STDP\n",
        "\n",
        "#### This implementation references the following:\n",
        "\n",
        "(1) Eugene M. Izhikevich, \"Simple Model of Spiking Neurons,\" IEEE TNN, 2003\n",
        "\n",
        "(2) Mozafari et al., \"SpykeTorch: Efficient Simulation of CNNs With at Most One Spike per Neuron,\" Frontiers in Neuroscience, 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPRMPDJrY2me"
      },
      "source": [
        "# 1. Setting Up the Environment\n",
        "\n",
        "First we have to import all the necessary PyTorch and utility packages.\n",
        "\n",
        "These libraries will be used to build the convolutional SNN with Izhikevich neurons and STDP/R-STDP learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8boU7y3BY2mf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgt7WVX4Y2mg"
      },
      "source": [
        "# 2. Global Configuration Parameters\n",
        "\n",
        "We have to define the basic parameters for the simulation environment and the Izhikevich neuron model.\n",
        "\n",
        "Key parameters:\n",
        "- `TMAX`: Maximum number of time steps for spiking simulation\n",
        "- Izhikevich model parameters for \"Regular Spiking\" neurons:\n",
        "  - `a` : Time scale of recovery\n",
        "  - `b` : Sensitivity of recovery\n",
        "  - `c` : Post-spike reset value of membrane potential\n",
        "  - `d` : Post-spike reset of recovery\n",
        "\n",
        "These define the dynamics of the spiking neurons based on the Izhikevich 2003 paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M6FnW8ivY2mg"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# This is the maximum number of time steps for the spiking simulation.\n",
        "TMAX = 15\n",
        "\n",
        "# The typical \"Regular Spiking (RS)\" is usually:\n",
        "a_ = 0.02\n",
        "b_ = 0.2\n",
        "c_ = -65.0\n",
        "d_ = 8.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIZRTecOY2mh"
      },
      "source": [
        "# 3. Converting Images to Spike Waves\n",
        "\n",
        "The `ToSpikeWave` transform needs to be implemented in order to convert standard image data into temporal spike patterns.\n",
        "\n",
        "- **Time-to-first-spike encoding**: Higher intensity pixels generate spikes earlier in the simulation\n",
        "- **Accumulative spike representation**: Once a neuron spikes at time t, it remains \"high\" (1) for all subsequent time steps\n",
        "- The output has shape [TMAX, channels, height, width] which represent the entire spike pattern over time\n",
        "\n",
        "This is essential for processing static images through a temporal spiking network, which allows the STDP learning mechanisms to be applied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-0b91utY2mh",
        "outputId": "a43b4903-8ee2-42f8-d784-2c59aefcd7bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spike transform created.\n"
          ]
        }
      ],
      "source": [
        "class ToSpikeWave:\n",
        "    \"\"\"\n",
        "    Converts a 2D (or 3D) intensity image into an accumulative spike-wave\n",
        "    [TMAX, C, H, W].\n",
        "    \"\"\"\n",
        "    def __init__(self, Tmax=15):\n",
        "        self.Tmax = Tmax\n",
        "\n",
        "    def __call__(self, img):\n",
        "        if img.max() > 1.0:\n",
        "            img = img / 255.0\n",
        "\n",
        "        spike_times = (1.0 - img) * (self.Tmax - 1)\n",
        "        spike_times = spike_times.clamp(0, self.Tmax - 1)\n",
        "\n",
        "        wave = torch.zeros((self.Tmax,) + img.shape, dtype=torch.float)\n",
        "        int_times = spike_times.mul(self.Tmax - 1).round().long()\n",
        "\n",
        "        C, H, W = img.shape\n",
        "        for c in range(C):\n",
        "            for r in range(H):\n",
        "                for w_ in range(W):\n",
        "                    st = int_times[c, r, w_].item()\n",
        "                    wave[st:, c, r, w_] = 1.0\n",
        "\n",
        "        return wave\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    ToSpikeWave(Tmax=TMAX)\n",
        "])\n",
        "\n",
        "print(\"Spike transform created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUi9QJ0VY2mi"
      },
      "source": [
        "# 4. Izhikevich Neuron Model Implementation\n",
        "\n",
        "Now the Izhikevich neuron model will need to be implemented as a PyTorch module. It is a computationally efficient way to simulate biologically plausible neural dynamics.\n",
        "\n",
        "The key equations implemented are:\n",
        "- v' = 0.04v² + 5v + 140 - u + I\n",
        "- u' = a(bv - u)\n",
        "- If v ≥ 30mV, then v ← c, u ← u + d\n",
        "\n",
        "Where:\n",
        "- v is the membrane potential\n",
        "- u is the recovery variable\n",
        "- I is the input current\n",
        "\n",
        "This is a simplified version of the model but it can still reproduce various firing patterns which can be seen in biological neurons (regular spiking, bursting, etc.) by adjusting a few of the parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ukFwv41Y2mj",
        "outputId": "4c1bdb83-e37d-4b1f-d644-5ca717d7add6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IzhikevichLayer defined.\n"
          ]
        }
      ],
      "source": [
        "class IzhikevichLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Maintains a population of Izhikevich neurons.\n",
        "    Each forward pass -> single time-step update for all neurons.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_neurons, a=0.02, b=0.2, c=-65.0, d=8.0, init_v=-65.0):\n",
        "        super().__init__()\n",
        "        self.a = a\n",
        "        self.b = b\n",
        "        self.c = c\n",
        "        self.d = d\n",
        "        self.num_neurons = num_neurons\n",
        "\n",
        "        self.register_buffer('v', torch.full((num_neurons,), init_v))\n",
        "        self.register_buffer('u', self.b * self.v)\n",
        "\n",
        "    def forward(self, input_current):\n",
        "        dv = 0.04*self.v*self.v + 5*self.v + 140 - self.u + input_current\n",
        "        du = self.a * (self.b*self.v - self.u)\n",
        "\n",
        "        self.v = self.v + dv\n",
        "        self.u = self.u + du\n",
        "\n",
        "        spike_mask = (self.v >= 30.0)\n",
        "        self.v[spike_mask] = self.c\n",
        "        self.u[spike_mask] += self.d\n",
        "\n",
        "        return spike_mask.float(), self.v\n",
        "\n",
        "    def reset_state(self):\n",
        "        self.v.fill_(self.c)\n",
        "        self.u.fill_(self.b * self.c)\n",
        "\n",
        "print(\"IzhikevichLayer defined.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4JPay51Y2mj"
      },
      "source": [
        "# 5. Spiking Convolution and Pooling Operations\n",
        "\n",
        "Now, the core neural processing operations for the SNN needs to be implemented. We need to:\n",
        "\n",
        "1. **`SpikingConv2D`**: Apply the convolution to the spike wave across time steps\n",
        "   - This takes input spike wave [T, Fin, H, W] and produces potentials [T, Fout, H', W']\n",
        "   - It uses randomly initialized weights with mean=0.8, std=0.02\n",
        "\n",
        "2. **`spiking_fire`**: Convert potential values to spike waves\n",
        "   - This is when neurons fire when potential exceeds threshold\n",
        "   - Once a neuron fires, it stays \"on\" for all subsequent time steps\n",
        "\n",
        "3. **`spiking_pooling`**: Downsample spike waves using max-pooling\n",
        "   - This preserves temporal information while reducing spatial dimensions\n",
        "\n",
        "These form the building blocks of the convolutional SNN architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55jmt3WHY2mk",
        "outputId": "fbbb2372-c25f-4a0f-b62b-7bc900e6eb5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SpikingConv2D, spiking_fire, spiking_pooling (with fix).\n"
          ]
        }
      ],
      "source": [
        "class SpikingConv2D(nn.Module):\n",
        "    \"\"\"\n",
        "    Convolution on accumulative spike-wave:\n",
        "    input shape [T, Fin, H, W] => output potentials [T, Fout, H_out, W_out]\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 weight_mean=0.8, weight_std=0.02):\n",
        "        super().__init__()\n",
        "        w = torch.normal(mean=weight_mean, std=weight_std,\n",
        "                         size=(out_channels, in_channels, kernel_size, kernel_size))\n",
        "        self.weight = nn.Parameter(w)\n",
        "\n",
        "    def forward(self, spike_wave):\n",
        "        pot = F.conv2d(spike_wave, self.weight, bias=None,\n",
        "                       stride=1, padding=0)\n",
        "        return pot\n",
        "\n",
        "def spiking_fire(potentials, threshold):\n",
        "    \"\"\"\n",
        "    Convert potentials [T, F, H, W] to accumulative spike-wave [T, F, H, W].\n",
        "    Once a neuron crosses threshold at time t, it's 1 for all subsequent t'.\n",
        "    \"\"\"\n",
        "    T, C, H, W = potentials.shape\n",
        "    spike_wave = torch.zeros_like(potentials)\n",
        "    first_spike = torch.full((C, H, W), T, dtype=torch.long,\n",
        "                             device=potentials.device)\n",
        "\n",
        "    for t in range(T):\n",
        "        above_thresh = (potentials[t] >= threshold)\n",
        "        newly_spiked = above_thresh & (first_spike == T)\n",
        "        first_spike[newly_spiked] = t\n",
        "\n",
        "    for t in range(T):\n",
        "        spike_wave[t] = (first_spike <= t).float()\n",
        "    return spike_wave\n",
        "\n",
        "\n",
        "def spiking_pooling(spike_wave, kernel_size=2, stride=2):\n",
        "    \"\"\"\n",
        "    Basic 2D max-pooling on accumulative spike wave.\n",
        "    shape => [T, C, H, W] => [T, C, H_out, W_out]\n",
        "    \"\"\"\n",
        "    T, C, H, W = spike_wave.shape\n",
        "    reshaped = spike_wave.view(T*C, 1, H, W)\n",
        "    pooled = F.max_pool2d(reshaped, kernel_size, stride)\n",
        "    Hout = pooled.shape[2]\n",
        "    Wout = pooled.shape[3]\n",
        "    pooled = pooled.view(T, C, Hout, Wout)\n",
        "    return pooled\n",
        "\n",
        "print(\"SpikingConv2D, spiking_fire, spiking_pooling (with fix).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuQgLLLkY2ml"
      },
      "source": [
        "# 6. STDP and Reward-Modulated STDP Learning Rules\n",
        "\n",
        "Now we have to implement the Spike-Timing-Dependent Plasticity (STDP) and its reward-modulated version (R-STDP).\n",
        "\n",
        "- **STDP**: Synaptic weights are updated based on the relative timing of pre- and post-synaptic spikes\n",
        "  - Pre-before-post timing strengthens connections (A_plus factor)\n",
        "  - Post-before-pre timing weakens connections (A_minus factor)\n",
        "  - Weight updates are bounded between lower bound (lb) and upper bound (ub)\n",
        "\n",
        "- **R-STDP**: Similar to STDP but modulated by a reward/punishment signal\n",
        "  - The reward factor scales the weight updates\n",
        "  - Positive reward reinforces the current pattern\n",
        "  - Negative reward weakens the current pattern\n",
        "\n",
        "These learning rules enable unsupervised (STDP) and reinforcement learning (R-STDP) in the spiking neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91OJGwXVY2ml",
        "outputId": "187a1c65-e73a-45ac-f441-b7e92de6e96d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STDP and R-STDP update functions defined.\n"
          ]
        }
      ],
      "source": [
        "def stdp_update(\n",
        "    weight: torch.Tensor,\n",
        "    pre_spike_time: torch.Tensor,\n",
        "    post_spike_time: torch.Tensor,\n",
        "    A_plus: float,\n",
        "    A_minus: float,\n",
        "    lb: float,\n",
        "    ub: float\n",
        "):\n",
        "    # Convert post_spike_time to tensor if it's a float\n",
        "    if isinstance(post_spike_time, (int, float)):\n",
        "        post_spike_time = torch.tensor(post_spike_time, device=weight.device, dtype=torch.float)\n",
        "\n",
        "    # Handle the dimensionality correctly\n",
        "    if post_spike_time.dim() == 0:\n",
        "        # Create a simple condition based on comparing with pre_spike_time\n",
        "        cond = pre_spike_time <= post_spike_time\n",
        "    else:\n",
        "        # For non-scalar, reshape as needed\n",
        "        cond = pre_spike_time <= post_spike_time.reshape(-1, 1, 1)\n",
        "\n",
        "    factor = (weight - lb) * (ub - weight)\n",
        "\n",
        "    weight_update = torch.zeros_like(weight)\n",
        "    weight_update[cond] = A_plus * factor[cond]\n",
        "    weight_update[~cond] = A_minus * factor[~cond]\n",
        "\n",
        "    weight = weight + weight_update\n",
        "    weight = torch.clamp(weight, lb, ub)\n",
        "    return weight\n",
        "\n",
        "def r_stdp_update(\n",
        "    weight: torch.Tensor,\n",
        "    pre_spike_time: torch.Tensor,\n",
        "    post_spike_time: torch.Tensor,\n",
        "    A_plus: float,\n",
        "    A_minus: float,\n",
        "    lb: float,\n",
        "    ub: float,\n",
        "    reward: float\n",
        "):\n",
        "    # Convert post_spike_time to tensor if it's a float\n",
        "    if isinstance(post_spike_time, (int, float)):\n",
        "        post_spike_time = torch.tensor(post_spike_time, device=weight.device, dtype=torch.float)\n",
        "\n",
        "    # Handle the dimensionality correctly\n",
        "    if post_spike_time.dim() == 0:\n",
        "        # Create a simple condition based on comparing with pre_spike_time\n",
        "        cond = pre_spike_time <= post_spike_time\n",
        "    else:\n",
        "        # For non-scalar, reshape as needed\n",
        "        cond = pre_spike_time <= post_spike_time.reshape(-1, 1, 1)\n",
        "\n",
        "    factor = (weight - lb) * (ub - weight)\n",
        "\n",
        "    weight_update = torch.zeros_like(weight)\n",
        "    weight_update[cond] = reward * A_plus * factor[cond]\n",
        "    weight_update[~cond] = reward * A_minus * factor[~cond]\n",
        "\n",
        "    weight = weight + weight_update\n",
        "    weight = torch.clamp(weight, lb, ub)\n",
        "    return weight\n",
        "\n",
        "print(\"STDP and R-STDP update functions defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFK-a8SWY2mm"
      },
      "source": [
        "# 7. Spike Processing and Winner Selection Functions\n",
        "\n",
        "Now we define a bunch of helper functions for processing spike data and implementing the winner-take-all mechanisms:\n",
        "\n",
        "1. **`first_spike_time_from_pot`**: Extracts the earliest time a potential crosses threshold\n",
        "   - Essential for determining when a neuron first spikes\n",
        "\n",
        "2. **`first_spike_time_from_wave`**: Extracts earliest spike times from a complete spike wave\n",
        "\n",
        "3. **`get_k_winners`**: Implements a competitive winner-take-all mechanism\n",
        "   - Selects k neurons with earliest spike times\n",
        "   - Uses peak potential as a tiebreaker\n",
        "   - Optional lateral inhibition with radius parameter\n",
        "   - Winners will be the neurons that get to update their weights via STDP\n",
        "\n",
        "These functions support the implementation of competitive learning and help process spike data for STDP updates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g7iJBbJY2mn",
        "outputId": "4f6a6d41-3e67-42ab-ef30-d8318d9752fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper functions for spikes, winners, times.\n"
          ]
        }
      ],
      "source": [
        "def first_spike_time_from_pot(pot_t):\n",
        "    \"\"\"\n",
        "    pot_t shape [T], earliest time pot_t(t) >= 0 => t, else T\n",
        "    \"\"\"\n",
        "    thr = 0.0\n",
        "    idx = (pot_t >= thr).nonzero(as_tuple=True)[0]\n",
        "    if len(idx) == 0:\n",
        "        return pot_t.shape[0]\n",
        "    return float(idx[0].item())\n",
        "\n",
        "def first_spike_time_from_wave(spike_wave):\n",
        "    \"\"\"\n",
        "    spike_wave: [T, C, H, W], return earliest spike time => shape [C, H, W].\n",
        "    \"\"\"\n",
        "    T, C, H, W = spike_wave.shape\n",
        "    out = torch.full((C, H, W), T, dtype=torch.float, device=spike_wave.device)\n",
        "    for t in range(T):\n",
        "        mask = (spike_wave[t] >= 0.5)\n",
        "        out[mask] = torch.minimum(out[mask], torch.full_like(out[mask], float(t)))\n",
        "    return out\n",
        "\n",
        "def get_k_winners(pot, k=5, radius=2):\n",
        "    \"\"\"\n",
        "    pot [T, C, H, W], pick k neurons with earliest spike times.\n",
        "    If tie => use peak potential as tiebreak (like partial).\n",
        "    \"\"\"\n",
        "    T, C, H, W = pot.shape\n",
        "    spike_times = torch.full((C, H, W), T, device=pot.device)\n",
        "    peak_pot = torch.zeros((C, H, W), device=pot.device)\n",
        "\n",
        "    for t in range(T):\n",
        "        slice_ = pot[t]\n",
        "        mask = (slice_ >= 0.0)\n",
        "        spike_times[mask] = torch.minimum(spike_times[mask], torch.full_like(spike_times[mask], float(t)))\n",
        "        peak_pot = torch.max(peak_pot, slice_)\n",
        "\n",
        "    st_flat = spike_times.view(-1)\n",
        "    pk_flat = peak_pot.view(-1)\n",
        "\n",
        "    coords = [(i // (H*W), (i % (H*W)) // W, (i % (H*W)) % W) for i in range(C*H*W)]\n",
        "    sorted_indices = sorted(range(C*H*W),\n",
        "                            key=lambda i: (st_flat[i].item(), -pk_flat[i].item()))\n",
        "    winners = []\n",
        "    used = torch.zeros((C, H, W), dtype=torch.bool)\n",
        "\n",
        "    for i in sorted_indices:\n",
        "        if len(winners) >= k:\n",
        "            break\n",
        "        f, r, c = coords[i]\n",
        "        if radius>0:\n",
        "            rr_min = max(0, r-radius)\n",
        "            rr_max = min(H, r+radius+1)\n",
        "            cc_min = max(0, c-radius)\n",
        "            cc_max = min(W, c+radius+1)\n",
        "            if used[f, rr_min:rr_max, cc_min:cc_max].any():\n",
        "                continue\n",
        "            else:\n",
        "                used[f, rr_min:rr_max, cc_min:cc_max] = True\n",
        "        winners.append((f, r, c))\n",
        "    return winners\n",
        "\n",
        "def get_better_winners(pot, k=5, radius=2, class_balance=True):\n",
        "    \"\"\"\n",
        "    Enhanced winner selection with better class balance\n",
        "    pot [T, C, H, W], pick k neurons with earliest spike times.\n",
        "    If class_balance=True, tries to select winners from different feature maps\n",
        "    \"\"\"\n",
        "    T, C, H, W = pot.shape\n",
        "    spike_times = torch.full((C, H, W), T, device=pot.device)\n",
        "    peak_pot = torch.zeros((C, H, W), device=pot.device)\n",
        "\n",
        "    # Calculate spike times and peak potentials\n",
        "    for t in range(T):\n",
        "        slice_ = pot[t]\n",
        "        mask = (slice_ >= 0.0)\n",
        "        spike_times[mask] = torch.minimum(spike_times[mask], torch.full_like(spike_times[mask], float(t)))\n",
        "        peak_pot = torch.max(peak_pot, slice_)\n",
        "\n",
        "    st_flat = spike_times.view(-1)\n",
        "    pk_flat = peak_pot.view(-1)\n",
        "\n",
        "    # Create coordinates list for all potential neurons\n",
        "    coords = [(i // (H*W), (i % (H*W)) // W, (i % (H*W)) % W) for i in range(C*H*W)]\n",
        "\n",
        "    # Sort by spike time (primary) and peak potential (secondary)\n",
        "    sorted_indices = sorted(range(C*H*W),\n",
        "                           key=lambda i: (st_flat[i].item(), -pk_flat[i].item()))\n",
        "\n",
        "    winners = []\n",
        "    used = torch.zeros((C, H, W), dtype=torch.bool, device=pot.device)\n",
        "    class_count = torch.zeros(C, dtype=torch.int, device=pot.device)\n",
        "\n",
        "    max_per_class = k // 3 + 1 if class_balance else k  # Limit winners per class if balancing\n",
        "\n",
        "    for i in sorted_indices:\n",
        "        if len(winners) >= k:\n",
        "            break\n",
        "\n",
        "        f, r, c = coords[i]\n",
        "\n",
        "        # Skip if we've reached max count for this class and we want class balance\n",
        "        if class_balance and class_count[f] >= max_per_class:\n",
        "            continue\n",
        "\n",
        "        # Check for inhibition zone\n",
        "        if radius > 0:\n",
        "            rr_min = max(0, r-radius)\n",
        "            rr_max = min(H, r+radius+1)\n",
        "            cc_min = max(0, c-radius)\n",
        "            cc_max = min(W, c+radius+1)\n",
        "\n",
        "            if used[f, rr_min:rr_max, cc_min:cc_max].any():\n",
        "                continue\n",
        "            else:\n",
        "                used[f, rr_min:rr_max, cc_min:cc_max] = True\n",
        "\n",
        "        winners.append((f, r, c))\n",
        "        class_count[f] += 1\n",
        "\n",
        "    return winners\n",
        "\n",
        "print(\"Helper functions for spikes, winners, times.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vkBSBHPY2mn"
      },
      "source": [
        "# 8. Deep Convolutional SNN Architecture\n",
        "\n",
        "Now we have to implement the complete three-layer Spiking CNN architecture with:\n",
        "\n",
        "1. **Layer Structure**:\n",
        "   - Layer 1: Convolutional layer + STDP learning\n",
        "   - Pooling\n",
        "   - Layer 2: Convolutional layer + STDP learning\n",
        "   - Pooling\n",
        "   - Layer 3: Output layer + R-STDP for classification\n",
        "\n",
        "2. **Learning Methods**:\n",
        "   - `forward_inference`: Regular forward pass for inference\n",
        "   - `forward_learn`: Forward pass with learning for a specific layer\n",
        "   - `apply_r_stdp`: Apply reward-modulated STDP\n",
        "   - `apply_r_stdp_direct`: Direct application of R-STDP to target neurons\n",
        "   - `stdp_update_layer`: Core function for updating weights with STDP\n",
        "\n",
        "This integrates all the previously defined components into a complete SNN architecture capable of unsupervised and reinforcement learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwW0Nua_Y2mn",
        "outputId": "c5aa7191-142d-43ba-d37f-7c9ff7648bf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DeepConvSNN created (with fix).\n"
          ]
        }
      ],
      "source": [
        "class DeepConvSNN(nn.Module):\n",
        "    \"\"\"\n",
        "    3-layer conv spiking net, approach from Mozafari et al. (2019).\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels=1,\n",
        "        layer1_channels=30, kernel1=5,\n",
        "        layer2_channels=100, kernel2=3,\n",
        "        layer3_channels=10, kernel3=5,\n",
        "        a=0.02, b=0.2, c=-65.0, d=8.0,\n",
        "        A_plus=0.004, A_minus=-0.003,\n",
        "        A_plus_r=0.004, A_minus_r=-0.003,\n",
        "        lb=0.0, ub=1.0,\n",
        "        reward_val=+1.0, punish_val=-1.0\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.conv1 = SpikingConv2D(in_channels, layer1_channels, kernel1)\n",
        "        self.conv2 = SpikingConv2D(layer1_channels, layer2_channels, kernel2)\n",
        "        self.conv3 = SpikingConv2D(layer2_channels, layer3_channels, kernel3)\n",
        "\n",
        "        self.A_plus = A_plus\n",
        "        self.A_minus = A_minus\n",
        "        self.A_plus_r = A_plus_r\n",
        "        self.A_minus_r = A_minus_r\n",
        "        self.lb = lb\n",
        "        self.ub = ub\n",
        "        self.reward_val = reward_val\n",
        "        self.punish_val = punish_val\n",
        "\n",
        "    def forward_inference(self, spike_wave):\n",
        "        pot1 = self.conv1(spike_wave)\n",
        "        spk1 = spiking_fire(pot1, 10.0)\n",
        "        spk1_pool = spiking_pooling(spk1, 2, 2)\n",
        "\n",
        "        pot2 = self.conv2(spk1_pool)\n",
        "        spk2 = spiking_fire(pot2, 5.0)\n",
        "        spk2_pool = spiking_pooling(spk2, 2, 2)\n",
        "\n",
        "        pot3 = self.conv3(spk2_pool)\n",
        "        return pot3\n",
        "\n",
        "    def forward_learn(self, spike_wave, layer_to_learn):\n",
        "        \"\"\"\n",
        "        Single sample => train a single layer with STDP or final layer with R-STDP.\n",
        "        \"\"\"\n",
        "        pot1 = self.conv1(spike_wave)\n",
        "        spk1 = spiking_fire(pot1, 5.0)\n",
        "        spk1_pool = spiking_pooling(spk1, 2, 2)\n",
        "\n",
        "        if layer_to_learn == 1:\n",
        "            winners = get_k_winners(pot1, 20, 2)\n",
        "            self.stdp_update_layer(self.conv1, spike_wave, pot1, winners, r_stdp=False)\n",
        "            return\n",
        "\n",
        "        pot2 = self.conv2(spk1_pool)\n",
        "        spk2 = spiking_fire(pot2, 3.0)\n",
        "        spk2_pool = spiking_pooling(spk2, 2, 2)\n",
        "\n",
        "        if layer_to_learn == 2:\n",
        "            winners = get_k_winners(pot2, 30, 1)\n",
        "            self.stdp_update_layer(self.conv2, spk1_pool, pot2, winners, r_stdp=False)\n",
        "            return\n",
        "\n",
        "        pot3 = self.conv3(spk2_pool)\n",
        "        return pot3\n",
        "\n",
        "    def apply_r_stdp(self, spike_wave, label, predicted):\n",
        "        pot3 = self.forward_inference(spike_wave)\n",
        "        winners = get_k_winners(pot3, k=1, radius=0)\n",
        "        rew = self.reward_val if (predicted == label) else self.punish_val\n",
        "        self.stdp_update_layer(self.conv3, None, pot3, winners, r_stdp=True, reward=rew)\n",
        "\n",
        "    def apply_r_stdp_direct(self, spike_wave, pot3, winners, reward):\n",
        "        \"\"\"Direct training of specific neurons with stronger reward\"\"\"\n",
        "        # Get the potentials from previous layers\n",
        "        pot1 = self.conv1(spike_wave)\n",
        "        spk1 = spiking_fire(pot1, 8.0)\n",
        "        spk1_pool = spiking_pooling(spk1, 2, 2)\n",
        "\n",
        "        pot2 = self.conv2(spk1_pool)\n",
        "        spk2 = spiking_fire(pot2, 6.0)\n",
        "        spk2_pool = spiking_pooling(spk2, 2, 2)\n",
        "\n",
        "        for (fout, rr, cc) in winners:\n",
        "            # Get pre-synaptic spike times for the specific kernel window\n",
        "            # Extract the correct kernel-sized window from spk2_pool based on the kernel size\n",
        "            kH, kW = self.conv3.weight.shape[2], self.conv3.weight.shape[3]  # Get actual kernel dimensions\n",
        "\n",
        "            # Make sure the window is properly sized\n",
        "            if rr + kH <= spk2_pool.shape[2] and cc + kW <= spk2_pool.shape[3]:\n",
        "                # Extract exactly the patch that would be used in convolution\n",
        "                pre_patch = spk2_pool[:, :, rr:rr+kH, cc:cc+kW]\n",
        "                T_pre = first_spike_time_from_wave(pre_patch)\n",
        "\n",
        "                # Use early spike time for the target neuron\n",
        "                T_post = 5.0 if reward > 0 else 10.0\n",
        "\n",
        "                # Apply stronger weight updates\n",
        "                self.conv3.weight.data[fout] = r_stdp_update(\n",
        "                    self.conv3.weight.data[fout],\n",
        "                    T_pre, T_post,\n",
        "                    self.A_plus_r*2, self.A_minus_r*2,\n",
        "                    self.lb, self.ub,\n",
        "                    reward\n",
        "                )\n",
        "\n",
        "\n",
        "    def stdp_update_layer(self, conv_layer, input_spike_wave, pot, winners, r_stdp=False, reward=0.0):\n",
        "        W = conv_layer.weight.data\n",
        "        kH = W.shape[2]\n",
        "        kW = W.shape[3]\n",
        "\n",
        "        for (fout, rr, cc) in winners:\n",
        "            T_post = first_spike_time_from_pot(pot[:, fout, rr, cc])\n",
        "            if input_spike_wave is not None:\n",
        "                pre_patch = input_spike_wave[:, :, rr:rr+kH, cc:cc+kW]\n",
        "                T_pre = first_spike_time_from_wave(pre_patch)\n",
        "            else:\n",
        "                T_pre = torch.zeros((W.shape[1], kH, kW), device=W.device)\n",
        "\n",
        "            if not r_stdp:\n",
        "                W[fout] = stdp_update(W[fout], T_pre, T_post,\n",
        "                                      self.A_plus, self.A_minus, self.lb, self.ub)\n",
        "            else:\n",
        "                W[fout] = r_stdp_update(W[fout], T_pre, T_post,\n",
        "                                        self.A_plus_r, self.A_minus_r, self.lb, self.ub, reward)\n",
        "        conv_layer.weight.data = W\n",
        "\n",
        "print(\"DeepConvSNN created (with fix).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uURUYiCfY2mn"
      },
      "source": [
        "# 9. Training Pipeline and Utilities\n",
        "\n",
        "Now we set up the complete training pipeline for the SNN:\n",
        "\n",
        "1. **Data Loading**:\n",
        "   - MNIST dataset with our custom spike encoding transform\n",
        "   - Training and testing data loaders\n",
        "\n",
        "2. **Model Instantiation**:\n",
        "   - Creates the DeepConvSNN with specific parameters\n",
        "   - Configures learning rates, weight bounds, etc.\n",
        "\n",
        "3. **Training Functions**:\n",
        "   - `predict_class`: Infers the class from layer 3 potentials\n",
        "   - `train_layer`: Trains a specific layer with STDP\n",
        "   - `train_layer3_rstdp`: Trains the classification layer with R-STDP\n",
        "   - `test_accuracy`: Evaluates model performance\n",
        "   - `reset_model`: Reinitializes weights for fresh training\n",
        "   - `train_on_mistakes`: Focused training on misclassified examples\n",
        "\n",
        "These functions provide a complete pipeline for layerwise training and evaluation of the spiking neural network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRb-wkriY2mo",
        "outputId": "e2e1f881-e01c-43b3-c926-1515e4f330bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.10MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 135kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.28MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 6.63MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded, model created, and training/testing functions defined.\n"
          ]
        }
      ],
      "source": [
        "# Datasets\n",
        "train_dataset = MNIST(root='.', train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(root='.', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "# Instantiate net\n",
        "model = DeepConvSNN(\n",
        "    in_channels=1,\n",
        "    layer1_channels=30, kernel1=5,\n",
        "    layer2_channels=100, kernel2=3,\n",
        "    layer3_channels=10, kernel3=3,\n",
        "    a=a_, b=b_, c=c_, d=d_,\n",
        "    A_plus=0.01, A_minus=-0.008,\n",
        "    A_plus_r=0.01, A_minus_r=-0.008,\n",
        "    lb=0.2, ub=0.8,\n",
        "    reward_val=+1.0, punish_val=-1.0\n",
        ").to(device)\n",
        "\n",
        "\n",
        "def predict_class(pot3):\n",
        "    \"\"\"\n",
        "    Enhanced version - calculate spike count and timing together\n",
        "    \"\"\"\n",
        "    T, C, H, W = pot3.shape\n",
        "    class_scores = torch.zeros(C, device=pot3.device)\n",
        "\n",
        "    for f in range(C):\n",
        "        # Maximum activation across spatial dimensions\n",
        "        channel_pot = pot3[:, f]\n",
        "        spike_mask = (channel_pot > 0).float()\n",
        "        spike_count = spike_mask.sum()\n",
        "\n",
        "        # Timing factor - earlier spikes are better\n",
        "        min_time = T\n",
        "        for t in range(T):\n",
        "            if spike_mask[t].sum() > 0:\n",
        "                min_time = t\n",
        "                break\n",
        "\n",
        "        # Combine factors - more spikes and earlier timing is better\n",
        "        class_scores[f] = spike_count * (T - min_time)\n",
        "\n",
        "    return torch.argmax(class_scores).item()\n",
        "\n",
        "\n",
        "def train_layer(model, loader, layer_idx, epochs=1, max_images=1000):\n",
        "    \"\"\"\n",
        "    Train a specific layer of the model\n",
        "    max_images: limit the number of training examples (set to None to use all)\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    for ep in range(epochs):\n",
        "        for i, (data_spike_wave, target) in enumerate(loader):\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Processing image {i}...\")\n",
        "\n",
        "            # Process the image\n",
        "            data_spike_wave = data_spike_wave.to(device)\n",
        "            model.forward_learn(data_spike_wave.squeeze(0), layer_to_learn=layer_idx)\n",
        "\n",
        "            # Limit the number of training examples for faster testing\n",
        "            if max_images is not None and i >= max_images-1:\n",
        "                print(f\"Reached maximum images ({max_images}), stopping training\")\n",
        "                return\n",
        "\n",
        "def train_layer3_rstdp(model, loader, epochs=1, max_images=1000):\n",
        "    model.train()\n",
        "    for ep in range(epochs):\n",
        "        correct_during_training = 0\n",
        "        total_during_training = 0\n",
        "\n",
        "        for i, (data_spike_wave, target) in enumerate(loader):\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Processing image {i}...\")\n",
        "\n",
        "            data_spike_wave = data_spike_wave.to(device)\n",
        "            pot3 = model.forward_inference(data_spike_wave.squeeze(0))\n",
        "            pred_class_ = predict_class(pot3)\n",
        "            lbl = target.item()\n",
        "\n",
        "            # Apply stronger reward/punishment based on correctness\n",
        "            reward_val = 1.5 if pred_class_ == lbl else -1.5\n",
        "\n",
        "            # Force activation of the correct class neuron\n",
        "            winners = [(lbl, 0, 0)]  # Always update the weights for the correct class\n",
        "            model.apply_r_stdp_direct(data_spike_wave.squeeze(0), pot3, winners, reward_val)\n",
        "\n",
        "            # Track accuracy during training\n",
        "            if pred_class_ == lbl:\n",
        "                correct_during_training += 1\n",
        "            total_during_training += 1\n",
        "\n",
        "            if i % 100 == 99:\n",
        "                print(f\"Current training accuracy: {100*correct_during_training/total_during_training:.2f}%\")\n",
        "\n",
        "            if max_images is not None and i >= max_images-1:\n",
        "                print(f\"Reached maximum images ({max_images}), stopping training\")\n",
        "                return\n",
        "\n",
        "def train_layer3_rstdp_improved(model, loader, epochs=1, max_images=1000):\n",
        "    \"\"\"Enhanced R-STDP training for layer 3 with adaptive rewards\"\"\"\n",
        "    model.train()\n",
        "\n",
        "    correct_during_training = 0\n",
        "    total_during_training = 0\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for ep in range(epochs):\n",
        "        print(f\"Epoch {ep+1}/{epochs}\")\n",
        "\n",
        "        for i, (data_spike_wave, target) in enumerate(loader):\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Processing image {i}...\")\n",
        "\n",
        "            data_spike_wave = data_spike_wave.to(device)\n",
        "            pot3 = model.forward_inference(data_spike_wave.squeeze(0))\n",
        "            pred_class_ = predict_class(pot3)\n",
        "            lbl = target.item()\n",
        "\n",
        "            # Use the improved direct R-STDP method with both label and prediction\n",
        "            model.apply_r_stdp_direct_improved(\n",
        "                data_spike_wave.squeeze(0), pot3, lbl, pred_class_\n",
        "            )\n",
        "\n",
        "            # Track performance\n",
        "            if pred_class_ == lbl:\n",
        "                correct_during_training += 1\n",
        "            total_during_training += 1\n",
        "\n",
        "            # More frequent progress reporting\n",
        "            if i % 50 == 49:\n",
        "                current_acc = 100 * correct_during_training / total_during_training\n",
        "                print(f\"Current training accuracy: {current_acc:.2f}% [{i+1}/{max_images}]\")\n",
        "\n",
        "            # Stop if we've processed enough images\n",
        "            if max_images is not None and i >= max_images-1:\n",
        "                print(f\"Reached maximum images ({max_images}), stopping training\")\n",
        "                return\n",
        "\n",
        "        epoch_acc = 100 * correct_during_training / total_during_training\n",
        "        print(f\"Epoch {ep+1} completed. Training accuracy: {epoch_acc:.2f}%\")\n",
        "\n",
        "def test_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data_spike_wave, target) in enumerate(loader):\n",
        "            data_spike_wave = data_spike_wave.to(device)\n",
        "            pot3 = model.forward_inference(data_spike_wave.squeeze(0))\n",
        "            pred_class_ = predict_class(pot3)\n",
        "            if pred_class_ == target.item():\n",
        "                correct += 1\n",
        "            total += 1\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "def reset_model(model):\n",
        "    \"\"\"Reset model weights for a fresh training run\"\"\"\n",
        "    print(\"Resetting model weights for a new training attempt...\")\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, SpikingConv2D):\n",
        "            # Initialize with new random weights - ensure they're on the same device as the model\n",
        "            device = m.weight.device\n",
        "            w = torch.normal(mean=0.8, std=0.02, size=m.weight.shape, device=device)\n",
        "            m.weight.data = w\n",
        "    return model\n",
        "\n",
        "def train_on_mistakes(model, loader, max_mistakes=200):\n",
        "    print(\"Training specifically on misclassified examples...\")\n",
        "    mistakes_trained = 0\n",
        "    model.train()\n",
        "\n",
        "    for data_spike_wave, target in loader:\n",
        "        data_spike_wave = data_spike_wave.to(device)\n",
        "        pot3 = model.forward_inference(data_spike_wave.squeeze(0))\n",
        "        pred = predict_class(pot3)\n",
        "\n",
        "        if pred != target.item():\n",
        "            lbl = target.item()\n",
        "            winners = [(lbl, 0, 0)]\n",
        "            reward_val = 2.0\n",
        "\n",
        "            model.apply_r_stdp_direct(data_spike_wave.squeeze(0), pot3, winners, reward_val)\n",
        "\n",
        "            mistakes_trained += 1\n",
        "            if mistakes_trained % 10 == 0:\n",
        "                print(f\"Trained on {mistakes_trained} mistakes...\")\n",
        "\n",
        "            if mistakes_trained >= max_mistakes:\n",
        "                print(f\"Reached maximum mistakes ({max_mistakes}), stopping training\")\n",
        "                break\n",
        "\n",
        "    return mistakes_trained\n",
        "\n",
        "print(\"Data loaded, model created, and training/testing functions defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ccx0FxkY2mo"
      },
      "source": [
        "# 10. Model Training and Evaluation\n",
        "\n",
        "Now we execute the complete training procedure for the SNN:\n",
        "\n",
        "1. **Multi-attempt Training**:\n",
        "   - Tries multiple training runs with different weight initializations\n",
        "   - Keeps track of the best-performing model\n",
        "\n",
        "2. **Layer-wise Training Process**:\n",
        "   - Unsupervised STDP training for layer 1\n",
        "   - Unsupervised STDP training for layer 2\n",
        "   - Reward-modulated STDP training for layer 3\n",
        "\n",
        "3. **Performance Enhancement**:\n",
        "   - Focused training on misclassified examples\n",
        "   - Final accuracy evaluation\n",
        "\n",
        "The training process follows the approach from Mozafari et al. (2019), with additions to improve performance through multiple attempts and targeted training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNA3aZCaY2mo",
        "outputId": "7bd04c55-a93b-4aff-b554-fad8307870d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training Attempt 1 ===\n",
            "=== Unsupervised training layer 1 (Attempt 1) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 1 (Attempt 1)\n",
            "=== Unsupervised training layer 2 (Attempt 1) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 2 (Attempt 1)\n",
            "=== R-STDP training layer 3 (Attempt 1) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Current training accuracy: 10.00%\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Current training accuracy: 8.50%\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Current training accuracy: 8.67%\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Current training accuracy: 9.25%\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Current training accuracy: 10.40%\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 3 with R-STDP (Attempt 1)\n",
            "Training attempt 1 accuracy: 9.80%\n",
            "New best model found! Accuracy: 9.80%\n",
            "\n",
            "=== Training Attempt 2 ===\n",
            "Resetting model weights for a new training attempt...\n",
            "=== Unsupervised training layer 1 (Attempt 2) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 1 (Attempt 2)\n",
            "=== Unsupervised training layer 2 (Attempt 2) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 2 (Attempt 2)\n",
            "=== R-STDP training layer 3 (Attempt 2) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Current training accuracy: 10.00%\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Current training accuracy: 10.00%\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Current training accuracy: 9.33%\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Current training accuracy: 9.50%\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Current training accuracy: 9.00%\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 3 with R-STDP (Attempt 2)\n",
            "Training attempt 2 accuracy: 9.80%\n",
            "\n",
            "=== Training Attempt 3 ===\n",
            "Resetting model weights for a new training attempt...\n",
            "=== Unsupervised training layer 1 (Attempt 3) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 1 (Attempt 3)\n",
            "=== Unsupervised training layer 2 (Attempt 3) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 2 (Attempt 3)\n",
            "=== R-STDP training layer 3 (Attempt 3) ===\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Current training accuracy: 13.00%\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Current training accuracy: 13.00%\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Current training accuracy: 11.67%\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Current training accuracy: 10.50%\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Current training accuracy: 10.80%\n",
            "Reached maximum images (500), stopping training\n",
            "Done training layer 3 with R-STDP (Attempt 3)\n",
            "Training attempt 3 accuracy: 9.80%\n",
            "\n",
            "Best model accuracy: 9.80%\n",
            "Training specifically on misclassified examples...\n",
            "Trained on 10 mistakes...\n",
            "Trained on 20 mistakes...\n",
            "Trained on 30 mistakes...\n",
            "Trained on 40 mistakes...\n",
            "Trained on 50 mistakes...\n",
            "Trained on 60 mistakes...\n",
            "Trained on 70 mistakes...\n",
            "Trained on 80 mistakes...\n",
            "Trained on 90 mistakes...\n",
            "Trained on 100 mistakes...\n",
            "Reached maximum mistakes (100), stopping training\n",
            "Trained on 100 misclassified examples\n",
            "Final accuracy after mistake correction: 9.80%\n"
          ]
        }
      ],
      "source": [
        "# Run multiple training attempts to find the best model\n",
        "best_accuracy = 0\n",
        "best_model = None\n",
        "\n",
        "for attempt in range(3):\n",
        "    print(f\"\\n=== Training Attempt {attempt+1} ===\")\n",
        "\n",
        "    # Reset model for new attempts\n",
        "    if attempt > 0:\n",
        "        model = reset_model(model)\n",
        "\n",
        "    # Train layer by layer\n",
        "    print(f\"=== Unsupervised training layer 1 (Attempt {attempt+1}) ===\")\n",
        "    train_layer(model, train_loader, layer_idx=1, epochs=2, max_images=500)\n",
        "    print(f\"Done training layer 1 (Attempt {attempt+1})\")\n",
        "\n",
        "    print(f\"=== Unsupervised training layer 2 (Attempt {attempt+1}) ===\")\n",
        "    train_layer(model, train_loader, layer_idx=2, epochs=2, max_images=500)\n",
        "    print(f\"Done training layer 2 (Attempt {attempt+1})\")\n",
        "\n",
        "    print(f\"=== R-STDP training layer 3 (Attempt {attempt+1}) ===\")\n",
        "    train_layer3_rstdp(model, train_loader, epochs=2, max_images=500)\n",
        "    print(f\"Done training layer 3 with R-STDP (Attempt {attempt+1})\")\n",
        "\n",
        "    # Test accuracy\n",
        "    acc = test_accuracy(model, test_loader)\n",
        "    print(f\"Training attempt {attempt+1} accuracy: {acc:.2f}%\")\n",
        "\n",
        "    if acc > best_accuracy:\n",
        "        best_accuracy = acc\n",
        "        best_model = copy.deepcopy(model)\n",
        "        print(f\"New best model found! Accuracy: {best_accuracy:.2f}%\")\n",
        "\n",
        "# Use the best model for final results\n",
        "model = best_model\n",
        "print(f\"\\nBest model accuracy: {best_accuracy:.2f}%\")\n",
        "\n",
        "# Apply focused training on mistakes to the best model\n",
        "mistakes_fixed = train_on_mistakes(model, train_loader, max_mistakes=100)\n",
        "print(f\"Trained on {mistakes_fixed} misclassified examples\")\n",
        "\n",
        "# Final accuracy check\n",
        "final_acc = test_accuracy(model, test_loader)\n",
        "print(f\"Final accuracy after mistake correction: {final_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Improved Training Strategy\n",
        "\n",
        "Previous methods accomplished baseline accuracy, this method attempts to improve the training process and hopefully increase the accuracy. We will perform 3 attempts per layer with limited GPU capabilities"
      ],
      "metadata": {
        "id": "lKsrPbq3gej8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def improved_training_pipeline(model, train_loader, test_loader,\n",
        "                              layer1_attempts=3, layer1_epochs=3, layer1_samples=1000,\n",
        "                              layer2_attempts=3, layer2_epochs=3, layer2_samples=1000,\n",
        "                              layer3_attempts=3, layer3_epochs=3, layer3_samples=1000,\n",
        "                              mistake_correction_rounds=3, mistakes_per_round=200):\n",
        "    \"\"\"\n",
        "    Enhanced training pipeline with multiple attempts per layer and iterative mistake correction\n",
        "    \"\"\"\n",
        "    print(\"Starting improved training pipeline with multiple attempts per layer...\")\n",
        "\n",
        "    # Train layer 1 with multiple attempts\n",
        "    print(\"=== Training layer 1 ===\")\n",
        "    best_layer1_model = None\n",
        "    best_layer1_acc = 0\n",
        "\n",
        "    for attempt in range(layer1_attempts):\n",
        "        print(f\"Layer 1 - Attempt {attempt+1}/{layer1_attempts}\")\n",
        "\n",
        "        # Reset layer 1 weights for each new attempt (except first)\n",
        "        if attempt > 0:\n",
        "            device = model.conv1.weight.device  # Get the correct device\n",
        "            w = torch.normal(mean=0.8, std=0.02, size=model.conv1.weight.shape, device=device)\n",
        "            model.conv1.weight.data = w\n",
        "\n",
        "        # Train layer 1\n",
        "        train_layer(model, train_loader, layer_idx=1, epochs=layer1_epochs, max_images=layer1_samples)\n",
        "\n",
        "        # Evaluate after layer 1\n",
        "        acc = test_accuracy(model, test_loader)\n",
        "        print(f\"Layer 1 - Attempt {attempt+1} accuracy: {acc:.2f}%\")\n",
        "\n",
        "        # Keep track of best model\n",
        "        if acc > best_layer1_acc:\n",
        "            best_layer1_acc = acc\n",
        "            best_layer1_model = copy.deepcopy(model)\n",
        "            print(f\"New best layer 1 model! Accuracy: {best_layer1_acc:.2f}%\")\n",
        "\n",
        "    # Use the best layer 1 model\n",
        "    model = best_layer1_model\n",
        "    print(f\"Best layer 1 model accuracy: {best_layer1_acc:.2f}%\")\n",
        "\n",
        "    # Train layer 2 with multiple attempts\n",
        "    print(\"\\n=== Training layer 2 ===\")\n",
        "    best_layer2_model = None\n",
        "    best_layer2_acc = 0\n",
        "\n",
        "    for attempt in range(layer2_attempts):\n",
        "        print(f\"Layer 2 - Attempt {attempt+1}/{layer2_attempts}\")\n",
        "\n",
        "        # Reset layer 2 weights for each new attempt (except first)\n",
        "        if attempt > 0:\n",
        "            device = model.conv2.weight.device  # Get the correct device\n",
        "            w = torch.normal(mean=0.8, std=0.02, size=model.conv2.weight.shape, device=device)\n",
        "            model.conv2.weight.data = w\n",
        "\n",
        "        # Train layer 2\n",
        "        train_layer(model, train_loader, layer_idx=2, epochs=layer2_epochs, max_images=layer2_samples)\n",
        "\n",
        "        # Evaluate after layer 2\n",
        "        acc = test_accuracy(model, test_loader)\n",
        "        print(f\"Layer 2 - Attempt {attempt+1} accuracy: {acc:.2f}%\")\n",
        "\n",
        "        # Keep track of best model\n",
        "        if acc > best_layer2_acc:\n",
        "            best_layer2_acc = acc\n",
        "            best_layer2_model = copy.deepcopy(model)\n",
        "            print(f\"New best layer 2 model! Accuracy: {best_layer2_acc:.2f}%\")\n",
        "\n",
        "    # Use the best layer 2 model\n",
        "    model = best_layer2_model\n",
        "    print(f\"Best layer 2 model accuracy: {best_layer2_acc:.2f}%\")\n",
        "\n",
        "    # Train layer 3 with multiple attempts\n",
        "    print(\"\\n=== Training layer 3 with R-STDP ===\")\n",
        "    best_layer3_model = None\n",
        "    best_layer3_acc = 0\n",
        "\n",
        "    for attempt in range(layer3_attempts):\n",
        "        print(f\"Layer 3 - Attempt {attempt+1}/{layer3_attempts}\")\n",
        "\n",
        "        # Reset layer 3 weights for each new attempt (except first)\n",
        "        if attempt > 0:\n",
        "            device = model.conv3.weight.device  # Get the correct device\n",
        "            w = torch.normal(mean=0.8, std=0.02, size=model.conv3.weight.shape, device=device)\n",
        "            model.conv3.weight.data = w\n",
        "\n",
        "        # Train layer 3\n",
        "        train_layer3_rstdp(model, train_loader, epochs=layer3_epochs, max_images=layer3_samples)\n",
        "\n",
        "        # Evaluate after layer 3\n",
        "        acc = test_accuracy(model, test_loader)\n",
        "        print(f\"Layer 3 - Attempt {attempt+1} accuracy: {acc:.2f}%\")\n",
        "\n",
        "        # Keep track of best model\n",
        "        if acc > best_layer3_acc:\n",
        "            best_layer3_acc = acc\n",
        "            best_layer3_model = copy.deepcopy(model)\n",
        "            print(f\"New best layer 3 model! Accuracy: {best_layer3_acc:.2f}%\")\n",
        "\n",
        "    # Use the best layer 3 model\n",
        "    model = best_layer3_model\n",
        "    print(f\"Best layer 3 model accuracy: {best_layer3_acc:.2f}%\")\n",
        "\n",
        "    # Iterative mistake correction\n",
        "    for round_idx in range(mistake_correction_rounds):\n",
        "        print(f\"\\n=== Mistake correction round {round_idx+1}/{mistake_correction_rounds} ===\")\n",
        "        mistakes_fixed = train_on_mistakes(model, train_loader, max_mistakes=mistakes_per_round)\n",
        "        print(f\"Trained on {mistakes_fixed} misclassified examples\")\n",
        "\n",
        "        # Evaluate after mistake correction\n",
        "        acc_after_correction = test_accuracy(model, test_loader)\n",
        "        print(f\"Accuracy after correction round {round_idx+1}: {acc_after_correction:.2f}%\")\n",
        "\n",
        "    # Final evaluation\n",
        "    final_acc = test_accuracy(model, test_loader)\n",
        "    print(f\"Final model accuracy: {final_acc:.2f}%\")\n",
        "\n",
        "    return model, final_acc\n",
        "\n",
        "# Run the improved training with multiple attempts per layer\n",
        "print(\"\\n=== Starting Improved Training Run with Multiple Attempts ===\")\n",
        "model, improved_acc = improved_training_pipeline(\n",
        "    model,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    layer1_attempts=3,\n",
        "    layer1_epochs=2,\n",
        "    layer1_samples=1000,\n",
        "    layer2_attempts=3,\n",
        "    layer2_epochs=2,\n",
        "    layer2_samples=1000,\n",
        "    layer3_attempts=3,\n",
        "    layer3_epochs=2,\n",
        "    layer3_samples=1000,\n",
        "    mistake_correction_rounds=2,\n",
        "    mistakes_per_round=200\n",
        ")\n",
        "print(f\"Improved training achieved {improved_acc:.2f}% accuracy\")"
      ],
      "metadata": {
        "id": "YbIOiWe_o4OY",
        "outputId": "80aad10c-b0b5-477a-88f1-32071ab6bf17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Starting Improved Training Run with Multiple Attempts ===\n",
            "Starting improved training pipeline with multiple attempts per layer...\n",
            "=== Training layer 1 ===\n",
            "Layer 1 - Attempt 1/3\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Processing image 500...\n",
            "Processing image 510...\n",
            "Processing image 520...\n",
            "Processing image 530...\n",
            "Processing image 540...\n",
            "Processing image 550...\n",
            "Processing image 560...\n",
            "Processing image 570...\n",
            "Processing image 580...\n",
            "Processing image 590...\n",
            "Processing image 600...\n",
            "Processing image 610...\n",
            "Processing image 620...\n",
            "Processing image 630...\n",
            "Processing image 640...\n",
            "Processing image 650...\n",
            "Processing image 660...\n",
            "Processing image 670...\n",
            "Processing image 680...\n",
            "Processing image 690...\n",
            "Processing image 700...\n",
            "Processing image 710...\n",
            "Processing image 720...\n",
            "Processing image 730...\n",
            "Processing image 740...\n",
            "Processing image 750...\n",
            "Processing image 760...\n",
            "Processing image 770...\n",
            "Processing image 780...\n",
            "Processing image 790...\n",
            "Processing image 800...\n",
            "Processing image 810...\n",
            "Processing image 820...\n",
            "Processing image 830...\n",
            "Processing image 840...\n",
            "Processing image 850...\n",
            "Processing image 860...\n",
            "Processing image 870...\n",
            "Processing image 880...\n",
            "Processing image 890...\n",
            "Processing image 900...\n",
            "Processing image 910...\n",
            "Processing image 920...\n",
            "Processing image 930...\n",
            "Processing image 940...\n",
            "Processing image 950...\n",
            "Processing image 960...\n",
            "Processing image 970...\n",
            "Processing image 980...\n",
            "Processing image 990...\n",
            "Reached maximum images (1000), stopping training\n",
            "Layer 1 - Attempt 1 accuracy: 9.80%\n",
            "New best layer 1 model! Accuracy: 9.80%\n",
            "Layer 1 - Attempt 2/3\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Processing image 500...\n",
            "Processing image 510...\n",
            "Processing image 520...\n",
            "Processing image 530...\n",
            "Processing image 540...\n",
            "Processing image 550...\n",
            "Processing image 560...\n",
            "Processing image 570...\n",
            "Processing image 580...\n",
            "Processing image 590...\n",
            "Processing image 600...\n",
            "Processing image 610...\n",
            "Processing image 620...\n",
            "Processing image 630...\n",
            "Processing image 640...\n",
            "Processing image 650...\n",
            "Processing image 660...\n",
            "Processing image 670...\n",
            "Processing image 680...\n",
            "Processing image 690...\n",
            "Processing image 700...\n",
            "Processing image 710...\n",
            "Processing image 720...\n",
            "Processing image 730...\n",
            "Processing image 740...\n",
            "Processing image 750...\n",
            "Processing image 760...\n",
            "Processing image 770...\n",
            "Processing image 780...\n",
            "Processing image 790...\n",
            "Processing image 800...\n",
            "Processing image 810...\n",
            "Processing image 820...\n",
            "Processing image 830...\n",
            "Processing image 840...\n",
            "Processing image 850...\n",
            "Processing image 860...\n",
            "Processing image 870...\n",
            "Processing image 880...\n",
            "Processing image 890...\n",
            "Processing image 900...\n",
            "Processing image 910...\n",
            "Processing image 920...\n",
            "Processing image 930...\n",
            "Processing image 940...\n",
            "Processing image 950...\n",
            "Processing image 960...\n",
            "Processing image 970...\n",
            "Processing image 980...\n",
            "Processing image 990...\n",
            "Reached maximum images (1000), stopping training\n",
            "Layer 1 - Attempt 2 accuracy: 9.80%\n",
            "Layer 1 - Attempt 3/3\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Processing image 500...\n",
            "Processing image 510...\n",
            "Processing image 520...\n",
            "Processing image 530...\n",
            "Processing image 540...\n",
            "Processing image 550...\n",
            "Processing image 560...\n",
            "Processing image 570...\n",
            "Processing image 580...\n",
            "Processing image 590...\n",
            "Processing image 600...\n",
            "Processing image 610...\n",
            "Processing image 620...\n",
            "Processing image 630...\n",
            "Processing image 640...\n",
            "Processing image 650...\n",
            "Processing image 660...\n",
            "Processing image 670...\n",
            "Processing image 680...\n",
            "Processing image 690...\n",
            "Processing image 700...\n",
            "Processing image 710...\n",
            "Processing image 720...\n",
            "Processing image 730...\n",
            "Processing image 740...\n",
            "Processing image 750...\n",
            "Processing image 760...\n",
            "Processing image 770...\n",
            "Processing image 780...\n",
            "Processing image 790...\n",
            "Processing image 800...\n",
            "Processing image 810...\n",
            "Processing image 820...\n",
            "Processing image 830...\n",
            "Processing image 840...\n",
            "Processing image 850...\n",
            "Processing image 860...\n",
            "Processing image 870...\n",
            "Processing image 880...\n",
            "Processing image 890...\n",
            "Processing image 900...\n",
            "Processing image 910...\n",
            "Processing image 920...\n",
            "Processing image 930...\n",
            "Processing image 940...\n",
            "Processing image 950...\n",
            "Processing image 960...\n",
            "Processing image 970...\n",
            "Processing image 980...\n",
            "Processing image 990...\n",
            "Reached maximum images (1000), stopping training\n",
            "Layer 1 - Attempt 3 accuracy: 9.80%\n",
            "Best layer 1 model accuracy: 9.80%\n",
            "\n",
            "=== Training layer 2 ===\n",
            "Layer 2 - Attempt 1/3\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Processing image 500...\n",
            "Processing image 510...\n",
            "Processing image 520...\n",
            "Processing image 530...\n",
            "Processing image 540...\n",
            "Processing image 550...\n",
            "Processing image 560...\n",
            "Processing image 570...\n",
            "Processing image 580...\n",
            "Processing image 590...\n",
            "Processing image 600...\n",
            "Processing image 610...\n",
            "Processing image 620...\n",
            "Processing image 630...\n",
            "Processing image 640...\n",
            "Processing image 650...\n",
            "Processing image 660...\n",
            "Processing image 670...\n",
            "Processing image 680...\n",
            "Processing image 690...\n",
            "Processing image 700...\n",
            "Processing image 710...\n",
            "Processing image 720...\n",
            "Processing image 730...\n",
            "Processing image 740...\n",
            "Processing image 750...\n",
            "Processing image 760...\n",
            "Processing image 770...\n",
            "Processing image 780...\n",
            "Processing image 790...\n",
            "Processing image 800...\n",
            "Processing image 810...\n",
            "Processing image 820...\n",
            "Processing image 830...\n",
            "Processing image 840...\n",
            "Processing image 850...\n",
            "Processing image 860...\n",
            "Processing image 870...\n",
            "Processing image 880...\n",
            "Processing image 890...\n",
            "Processing image 900...\n",
            "Processing image 910...\n",
            "Processing image 920...\n",
            "Processing image 930...\n",
            "Processing image 940...\n",
            "Processing image 950...\n",
            "Processing image 960...\n",
            "Processing image 970...\n",
            "Processing image 980...\n",
            "Processing image 990...\n",
            "Reached maximum images (1000), stopping training\n",
            "Layer 2 - Attempt 1 accuracy: 9.80%\n",
            "New best layer 2 model! Accuracy: 9.80%\n",
            "Layer 2 - Attempt 2/3\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Processing image 500...\n",
            "Processing image 510...\n",
            "Processing image 520...\n",
            "Processing image 530...\n",
            "Processing image 540...\n",
            "Processing image 550...\n",
            "Processing image 560...\n",
            "Processing image 570...\n",
            "Processing image 580...\n",
            "Processing image 590...\n",
            "Processing image 600...\n",
            "Processing image 610...\n",
            "Processing image 620...\n",
            "Processing image 630...\n",
            "Processing image 640...\n",
            "Processing image 650...\n",
            "Processing image 660...\n",
            "Processing image 670...\n",
            "Processing image 680...\n",
            "Processing image 690...\n",
            "Processing image 700...\n",
            "Processing image 710...\n",
            "Processing image 720...\n",
            "Processing image 730...\n",
            "Processing image 740...\n",
            "Processing image 750...\n",
            "Processing image 760...\n",
            "Processing image 770...\n",
            "Processing image 780...\n",
            "Processing image 790...\n",
            "Processing image 800...\n",
            "Processing image 810...\n",
            "Processing image 820...\n",
            "Processing image 830...\n",
            "Processing image 840...\n",
            "Processing image 850...\n",
            "Processing image 860...\n",
            "Processing image 870...\n",
            "Processing image 880...\n",
            "Processing image 890...\n",
            "Processing image 900...\n",
            "Processing image 910...\n",
            "Processing image 920...\n",
            "Processing image 930...\n",
            "Processing image 940...\n",
            "Processing image 950...\n",
            "Processing image 960...\n",
            "Processing image 970...\n",
            "Processing image 980...\n",
            "Processing image 990...\n",
            "Reached maximum images (1000), stopping training\n",
            "Layer 2 - Attempt 2 accuracy: 9.80%\n",
            "Layer 2 - Attempt 3/3\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Processing image 500...\n",
            "Processing image 510...\n",
            "Processing image 520...\n",
            "Processing image 530...\n",
            "Processing image 540...\n",
            "Processing image 550...\n",
            "Processing image 560...\n",
            "Processing image 570...\n",
            "Processing image 580...\n",
            "Processing image 590...\n",
            "Processing image 600...\n",
            "Processing image 610...\n",
            "Processing image 620...\n",
            "Processing image 630...\n",
            "Processing image 640...\n",
            "Processing image 650...\n",
            "Processing image 660...\n",
            "Processing image 670...\n",
            "Processing image 680...\n",
            "Processing image 690...\n",
            "Processing image 700...\n",
            "Processing image 710...\n",
            "Processing image 720...\n",
            "Processing image 730...\n",
            "Processing image 740...\n",
            "Processing image 750...\n",
            "Processing image 760...\n",
            "Processing image 770...\n",
            "Processing image 780...\n",
            "Processing image 790...\n",
            "Processing image 800...\n",
            "Processing image 810...\n",
            "Processing image 820...\n",
            "Processing image 830...\n",
            "Processing image 840...\n",
            "Processing image 850...\n",
            "Processing image 860...\n",
            "Processing image 870...\n",
            "Processing image 880...\n",
            "Processing image 890...\n",
            "Processing image 900...\n",
            "Processing image 910...\n",
            "Processing image 920...\n",
            "Processing image 930...\n",
            "Processing image 940...\n",
            "Processing image 950...\n",
            "Processing image 960...\n",
            "Processing image 970...\n",
            "Processing image 980...\n",
            "Processing image 990...\n",
            "Reached maximum images (1000), stopping training\n",
            "Layer 2 - Attempt 3 accuracy: 9.80%\n",
            "Best layer 2 model accuracy: 9.80%\n",
            "\n",
            "=== Training layer 3 with R-STDP ===\n",
            "Layer 3 - Attempt 1/3\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Current training accuracy: 11.00%\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Current training accuracy: 8.50%\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Current training accuracy: 11.33%\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Current training accuracy: 9.75%\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Current training accuracy: 10.00%\n",
            "Processing image 500...\n",
            "Processing image 510...\n",
            "Processing image 520...\n",
            "Processing image 530...\n",
            "Processing image 540...\n",
            "Processing image 550...\n",
            "Processing image 560...\n",
            "Processing image 570...\n",
            "Processing image 580...\n",
            "Processing image 590...\n",
            "Current training accuracy: 10.83%\n",
            "Processing image 600...\n",
            "Processing image 610...\n",
            "Processing image 620...\n",
            "Processing image 630...\n",
            "Processing image 640...\n",
            "Processing image 650...\n",
            "Processing image 660...\n",
            "Processing image 670...\n",
            "Processing image 680...\n",
            "Processing image 690...\n",
            "Current training accuracy: 11.43%\n",
            "Processing image 700...\n",
            "Processing image 710...\n",
            "Processing image 720...\n",
            "Processing image 730...\n",
            "Processing image 740...\n",
            "Processing image 750...\n",
            "Processing image 760...\n",
            "Processing image 770...\n",
            "Processing image 780...\n",
            "Processing image 790...\n",
            "Current training accuracy: 11.12%\n",
            "Processing image 800...\n",
            "Processing image 810...\n",
            "Processing image 820...\n",
            "Processing image 830...\n",
            "Processing image 840...\n",
            "Processing image 850...\n",
            "Processing image 860...\n",
            "Processing image 870...\n",
            "Processing image 880...\n",
            "Processing image 890...\n",
            "Current training accuracy: 10.78%\n",
            "Processing image 900...\n",
            "Processing image 910...\n",
            "Processing image 920...\n",
            "Processing image 930...\n",
            "Processing image 940...\n",
            "Processing image 950...\n",
            "Processing image 960...\n",
            "Processing image 970...\n",
            "Processing image 980...\n",
            "Processing image 990...\n",
            "Current training accuracy: 10.80%\n",
            "Reached maximum images (1000), stopping training\n",
            "Layer 3 - Attempt 1 accuracy: 9.80%\n",
            "New best layer 3 model! Accuracy: 9.80%\n",
            "Layer 3 - Attempt 2/3\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Current training accuracy: 8.00%\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Current training accuracy: 10.00%\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Current training accuracy: 10.67%\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Current training accuracy: 11.00%\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Current training accuracy: 11.20%\n",
            "Processing image 500...\n",
            "Processing image 510...\n",
            "Processing image 520...\n",
            "Processing image 530...\n",
            "Processing image 540...\n",
            "Processing image 550...\n",
            "Processing image 560...\n",
            "Processing image 570...\n",
            "Processing image 580...\n",
            "Processing image 590...\n",
            "Current training accuracy: 10.50%\n",
            "Processing image 600...\n",
            "Processing image 610...\n",
            "Processing image 620...\n",
            "Processing image 630...\n",
            "Processing image 640...\n",
            "Processing image 650...\n",
            "Processing image 660...\n",
            "Processing image 670...\n",
            "Processing image 680...\n",
            "Processing image 690...\n",
            "Current training accuracy: 9.57%\n",
            "Processing image 700...\n",
            "Processing image 710...\n",
            "Processing image 720...\n",
            "Processing image 730...\n",
            "Processing image 740...\n",
            "Processing image 750...\n",
            "Processing image 760...\n",
            "Processing image 770...\n",
            "Processing image 780...\n",
            "Processing image 790...\n",
            "Current training accuracy: 9.88%\n",
            "Processing image 800...\n",
            "Processing image 810...\n",
            "Processing image 820...\n",
            "Processing image 830...\n",
            "Processing image 840...\n",
            "Processing image 850...\n",
            "Processing image 860...\n",
            "Processing image 870...\n",
            "Processing image 880...\n",
            "Processing image 890...\n",
            "Current training accuracy: 9.67%\n",
            "Processing image 900...\n",
            "Processing image 910...\n",
            "Processing image 920...\n",
            "Processing image 930...\n",
            "Processing image 940...\n",
            "Processing image 950...\n",
            "Processing image 960...\n",
            "Processing image 970...\n",
            "Processing image 980...\n",
            "Processing image 990...\n",
            "Current training accuracy: 9.30%\n",
            "Reached maximum images (1000), stopping training\n",
            "Layer 3 - Attempt 2 accuracy: 9.80%\n",
            "Layer 3 - Attempt 3/3\n",
            "Processing image 0...\n",
            "Processing image 10...\n",
            "Processing image 20...\n",
            "Processing image 30...\n",
            "Processing image 40...\n",
            "Processing image 50...\n",
            "Processing image 60...\n",
            "Processing image 70...\n",
            "Processing image 80...\n",
            "Processing image 90...\n",
            "Current training accuracy: 13.00%\n",
            "Processing image 100...\n",
            "Processing image 110...\n",
            "Processing image 120...\n",
            "Processing image 130...\n",
            "Processing image 140...\n",
            "Processing image 150...\n",
            "Processing image 160...\n",
            "Processing image 170...\n",
            "Processing image 180...\n",
            "Processing image 190...\n",
            "Current training accuracy: 10.50%\n",
            "Processing image 200...\n",
            "Processing image 210...\n",
            "Processing image 220...\n",
            "Processing image 230...\n",
            "Processing image 240...\n",
            "Processing image 250...\n",
            "Processing image 260...\n",
            "Processing image 270...\n",
            "Processing image 280...\n",
            "Processing image 290...\n",
            "Current training accuracy: 10.67%\n",
            "Processing image 300...\n",
            "Processing image 310...\n",
            "Processing image 320...\n",
            "Processing image 330...\n",
            "Processing image 340...\n",
            "Processing image 350...\n",
            "Processing image 360...\n",
            "Processing image 370...\n",
            "Processing image 380...\n",
            "Processing image 390...\n",
            "Current training accuracy: 11.50%\n",
            "Processing image 400...\n",
            "Processing image 410...\n",
            "Processing image 420...\n",
            "Processing image 430...\n",
            "Processing image 440...\n",
            "Processing image 450...\n",
            "Processing image 460...\n",
            "Processing image 470...\n",
            "Processing image 480...\n",
            "Processing image 490...\n",
            "Current training accuracy: 12.20%\n",
            "Processing image 500...\n",
            "Processing image 510...\n",
            "Processing image 520...\n",
            "Processing image 530...\n",
            "Processing image 540...\n",
            "Processing image 550...\n",
            "Processing image 560...\n",
            "Processing image 570...\n",
            "Processing image 580...\n",
            "Processing image 590...\n",
            "Current training accuracy: 11.67%\n",
            "Processing image 600...\n",
            "Processing image 610...\n",
            "Processing image 620...\n",
            "Processing image 630...\n",
            "Processing image 640...\n",
            "Processing image 650...\n",
            "Processing image 660...\n",
            "Processing image 670...\n",
            "Processing image 680...\n",
            "Processing image 690...\n",
            "Current training accuracy: 11.14%\n",
            "Processing image 700...\n",
            "Processing image 710...\n",
            "Processing image 720...\n",
            "Processing image 730...\n",
            "Processing image 740...\n",
            "Processing image 750...\n",
            "Processing image 760...\n",
            "Processing image 770...\n",
            "Processing image 780...\n",
            "Processing image 790...\n",
            "Current training accuracy: 10.75%\n",
            "Processing image 800...\n",
            "Processing image 810...\n",
            "Processing image 820...\n",
            "Processing image 830...\n",
            "Processing image 840...\n",
            "Processing image 850...\n",
            "Processing image 860...\n",
            "Processing image 870...\n",
            "Processing image 880...\n",
            "Processing image 890...\n",
            "Current training accuracy: 11.67%\n",
            "Processing image 900...\n",
            "Processing image 910...\n",
            "Processing image 920...\n",
            "Processing image 930...\n",
            "Processing image 940...\n",
            "Processing image 950...\n",
            "Processing image 960...\n",
            "Processing image 970...\n",
            "Processing image 980...\n",
            "Processing image 990...\n",
            "Current training accuracy: 11.10%\n",
            "Reached maximum images (1000), stopping training\n",
            "Layer 3 - Attempt 3 accuracy: 9.80%\n",
            "Best layer 3 model accuracy: 9.80%\n",
            "\n",
            "=== Mistake correction round 1/2 ===\n",
            "Training specifically on misclassified examples...\n",
            "Trained on 10 mistakes...\n",
            "Trained on 20 mistakes...\n",
            "Trained on 30 mistakes...\n",
            "Trained on 40 mistakes...\n",
            "Trained on 50 mistakes...\n",
            "Trained on 60 mistakes...\n",
            "Trained on 70 mistakes...\n",
            "Trained on 80 mistakes...\n",
            "Trained on 90 mistakes...\n",
            "Trained on 100 mistakes...\n",
            "Trained on 110 mistakes...\n",
            "Trained on 120 mistakes...\n",
            "Trained on 130 mistakes...\n",
            "Trained on 140 mistakes...\n",
            "Trained on 150 mistakes...\n",
            "Trained on 160 mistakes...\n",
            "Trained on 170 mistakes...\n",
            "Trained on 180 mistakes...\n",
            "Trained on 190 mistakes...\n",
            "Trained on 200 mistakes...\n",
            "Reached maximum mistakes (200), stopping training\n",
            "Trained on 200 misclassified examples\n",
            "Accuracy after correction round 1: 9.80%\n",
            "\n",
            "=== Mistake correction round 2/2 ===\n",
            "Training specifically on misclassified examples...\n",
            "Trained on 10 mistakes...\n",
            "Trained on 20 mistakes...\n",
            "Trained on 30 mistakes...\n",
            "Trained on 40 mistakes...\n",
            "Trained on 50 mistakes...\n",
            "Trained on 60 mistakes...\n",
            "Trained on 70 mistakes...\n",
            "Trained on 80 mistakes...\n",
            "Trained on 90 mistakes...\n",
            "Trained on 100 mistakes...\n",
            "Trained on 110 mistakes...\n",
            "Trained on 120 mistakes...\n",
            "Trained on 130 mistakes...\n",
            "Trained on 140 mistakes...\n",
            "Trained on 150 mistakes...\n",
            "Trained on 160 mistakes...\n",
            "Trained on 170 mistakes...\n",
            "Trained on 180 mistakes...\n",
            "Trained on 190 mistakes...\n",
            "Trained on 200 mistakes...\n",
            "Reached maximum mistakes (200), stopping training\n",
            "Trained on 200 misclassified examples\n",
            "Accuracy after correction round 2: 9.80%\n",
            "Final model accuracy: 9.80%\n",
            "Improved training achieved 9.80% accuracy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. A more Flexible DeepConvSNN to allow for > 3 Layers"
      ],
      "metadata": {
        "id": "miHjq6C1hXEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FlexibleDeepConvSNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Flexible SNN with variable depth, supporting 3-5 layers\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels=1,\n",
        "        layer_channels=[30, 100, 10],  # Default is 3 layers\n",
        "        kernel_sizes=[5, 3, 3],\n",
        "        pool_sizes=[2, 2, 1],          # No pooling after final layer by default\n",
        "        pool_strides=[2, 2, 1],\n",
        "        thresholds=[5.0, 3.0, 1.0],    # Firing thresholds for each layer\n",
        "        a=0.02, b=0.2, c=-65.0, d=8.0,\n",
        "        A_plus=0.004, A_minus=-0.003,\n",
        "        A_plus_r=0.004, A_minus_r=-0.003,\n",
        "        lb=0.0, ub=1.0,\n",
        "        reward_val=+1.0, punish_val=-1.0\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # Validate inputs\n",
        "        assert len(layer_channels) >= 3 and len(layer_channels) <= 5, \"Model supports 3-5 layers\"\n",
        "        assert len(kernel_sizes) == len(layer_channels), \"Must provide kernel size for each layer\"\n",
        "        assert len(pool_sizes) == len(layer_channels), \"Must provide pool size for each layer\"\n",
        "        assert len(pool_strides) == len(layer_channels), \"Must provide pool stride for each layer\"\n",
        "        assert len(thresholds) == len(layer_channels), \"Must provide threshold for each layer\"\n",
        "\n",
        "        self.num_layers = len(layer_channels)\n",
        "        self.layer_channels = layer_channels\n",
        "        self.kernel_sizes = kernel_sizes\n",
        "        self.pool_sizes = pool_sizes\n",
        "        self.pool_strides = pool_strides\n",
        "        self.thresholds = thresholds\n",
        "\n",
        "        # Create convolutional layers\n",
        "        self.conv_layers = nn.ModuleList()\n",
        "\n",
        "        # First layer\n",
        "        self.conv_layers.append(SpikingConv2D(in_channels, layer_channels[0], kernel_sizes[0]))\n",
        "\n",
        "        # Remaining layers\n",
        "        for i in range(1, self.num_layers):\n",
        "            self.conv_layers.append(\n",
        "                SpikingConv2D(layer_channels[i-1], layer_channels[i], kernel_sizes[i])\n",
        "            )\n",
        "\n",
        "        # STDP parameters\n",
        "        self.A_plus = A_plus\n",
        "        self.A_minus = A_minus\n",
        "        self.A_plus_r = A_plus_r\n",
        "        self.A_minus_r = A_minus_r\n",
        "        self.lb = lb\n",
        "        self.ub = ub\n",
        "        self.reward_val = reward_val\n",
        "        self.punish_val = punish_val\n",
        "\n",
        "    def forward_inference(self, spike_wave):\n",
        "        \"\"\"\n",
        "        Forward pass for inference through all layers\n",
        "        \"\"\"\n",
        "        x = spike_wave\n",
        "        potentials = []\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            # Apply convolution\n",
        "            pot = self.conv_layers[i](x)\n",
        "            potentials.append(pot)\n",
        "\n",
        "            # Apply firing and pooling (except for the last layer)\n",
        "            spk = spiking_fire(pot, self.thresholds[i])\n",
        "\n",
        "            # Apply pooling if needed\n",
        "            if self.pool_sizes[i] > 1:\n",
        "                x = spiking_pooling(spk, self.pool_sizes[i], self.pool_strides[i])\n",
        "            else:\n",
        "                x = spk\n",
        "\n",
        "        # Return the final layer potential for classification\n",
        "        return potentials[-1]\n",
        "\n",
        "    def forward_learn(self, spike_wave, layer_to_learn):\n",
        "        \"\"\"\n",
        "        Forward pass with learning for a specific layer\n",
        "        \"\"\"\n",
        "        if layer_to_learn < 1 or layer_to_learn > self.num_layers:\n",
        "            raise ValueError(f\"Layer to learn must be between 1 and {self.num_layers}\")\n",
        "\n",
        "        x = spike_wave\n",
        "        potentials = []\n",
        "\n",
        "        # Process up to the layer we want to learn\n",
        "        for i in range(layer_to_learn):\n",
        "            # Apply convolution\n",
        "            pot = self.conv_layers[i](x)\n",
        "            potentials.append(pot)\n",
        "\n",
        "            # If this is the layer to learn, apply STDP and return\n",
        "            if i+1 == layer_to_learn:\n",
        "                winners = get_better_winners(pot, k=20 if i==0 else 30, radius=2 if i==0 else 1)\n",
        "                self.stdp_update_layer(self.conv_layers[i], x, pot, winners, r_stdp=False)\n",
        "                return\n",
        "\n",
        "            # Otherwise continue forward pass\n",
        "            spk = spiking_fire(pot, self.thresholds[i])\n",
        "\n",
        "            # Apply pooling if needed\n",
        "            if self.pool_sizes[i] > 1:\n",
        "                x = spiking_pooling(spk, self.pool_sizes[i], self.pool_strides[i])\n",
        "            else:\n",
        "                x = spk\n",
        "\n",
        "    def apply_r_stdp(self, spike_wave, label, predicted):\n",
        "        \"\"\"\n",
        "        Apply R-STDP to the final layer based on prediction correctness\n",
        "        \"\"\"\n",
        "        pot_final = self.forward_inference(spike_wave)\n",
        "        winners = get_k_winners(pot_final, k=1, radius=0)\n",
        "        rew = self.reward_val if (predicted == label) else self.punish_val\n",
        "\n",
        "        # Get the input to the final layer\n",
        "        x = spike_wave\n",
        "        for i in range(self.num_layers - 1):\n",
        "            pot = self.conv_layers[i](x)\n",
        "            spk = spiking_fire(pot, self.thresholds[i])\n",
        "            if self.pool_sizes[i] > 1:\n",
        "                x = spiking_pooling(spk, self.pool_sizes[i], self.pool_strides[i])\n",
        "            else:\n",
        "                x = spk\n",
        "\n",
        "        self.stdp_update_layer(self.conv_layers[-1], x, pot_final, winners, r_stdp=True, reward=rew)\n",
        "\n",
        "    def apply_r_stdp_direct(self, spike_wave, pot_final, winners, reward):\n",
        "        \"\"\"\n",
        "        Direct training of specific neurons with stronger reward\n",
        "        \"\"\"\n",
        "        # Process through all layers except the last one to get the input to the final layer\n",
        "        x = spike_wave\n",
        "        for i in range(self.num_layers - 1):\n",
        "            pot = self.conv_layers[i](x)\n",
        "            spk = spiking_fire(pot, self.thresholds[i])\n",
        "            if self.pool_sizes[i] > 1:\n",
        "                x = spiking_pooling(spk, self.pool_sizes[i], self.pool_strides[i])\n",
        "            else:\n",
        "                x = spk\n",
        "\n",
        "        # Now apply R-STDP to the final layer\n",
        "        for (fout, rr, cc) in winners:\n",
        "            # Get pre-synaptic spike times for the specific kernel window\n",
        "            kH, kW = self.conv_layers[-1].weight.shape[2], self.conv_layers[-1].weight.shape[3]\n",
        "\n",
        "            # Make sure the window is properly sized\n",
        "            if rr + kH <= x.shape[2] and cc + kW <= x.shape[3]:\n",
        "                # Extract exactly the patch that would be used in convolution\n",
        "                pre_patch = x[:, :, rr:rr+kH, cc:cc+kW]\n",
        "                T_pre = first_spike_time_from_wave(pre_patch)\n",
        "\n",
        "                # Use early spike time for the target neuron\n",
        "                T_post = 5.0 if reward > 0 else 10.0\n",
        "\n",
        "                # Apply stronger weight updates\n",
        "                self.conv_layers[-1].weight.data[fout] = r_stdp_update(\n",
        "                    self.conv_layers[-1].weight.data[fout],\n",
        "                    T_pre, T_post,\n",
        "                    self.A_plus_r*2, self.A_minus_r*2,\n",
        "                    self.lb, self.ub,\n",
        "                    reward\n",
        "                )\n",
        "\n",
        "    def stdp_update_layer(self, conv_layer, input_spike_wave, pot, winners, r_stdp=False, reward=0.0):\n",
        "        \"\"\"\n",
        "        Core function for updating weights with STDP or R-STDP\n",
        "        \"\"\"\n",
        "        W = conv_layer.weight.data\n",
        "        kH = W.shape[2]\n",
        "        kW = W.shape[3]\n",
        "\n",
        "        for (fout, rr, cc) in winners:\n",
        "            T_post = first_spike_time_from_pot(pot[:, fout, rr, cc])\n",
        "            if input_spike_wave is not None:\n",
        "                pre_patch = input_spike_wave[:, :, rr:rr+kH, cc:cc+kW]\n",
        "                T_pre = first_spike_time_from_wave(pre_patch)\n",
        "            else:\n",
        "                T_pre = torch.zeros((W.shape[1], kH, kW), device=W.device)\n",
        "\n",
        "            if not r_stdp:\n",
        "                W[fout] = stdp_update(W[fout], T_pre, T_post,\n",
        "                                     self.A_plus, self.A_minus, self.lb, self.ub)\n",
        "            else:\n",
        "                W[fout] = r_stdp_update(W[fout], T_pre, T_post,\n",
        "                                       self.A_plus_r, self.A_minus_r, self.lb, self.ub, reward)\n",
        "\n",
        "        conv_layer.weight.data = W\n",
        "\n",
        "print(\"Flexible DeepConvSNN class created.\")"
      ],
      "metadata": {
        "id": "uO_u-keAheQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a 4 and 5 Layer DeepConvSNN model"
      ],
      "metadata": {
        "id": "LD550W2EiG_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 13. Creating and Training 4-Layer and 5-Layer Models\n",
        "\n",
        "# 4-Layer Model\n",
        "model_4layer = FlexibleDeepConvSNN(\n",
        "    in_channels=1,\n",
        "    layer_channels=[30, 80, 150, 10],  # 4 layers\n",
        "    kernel_sizes=[5, 3, 3, 3],\n",
        "    pool_sizes=[2, 2, 2, 1],\n",
        "    pool_strides=[2, 2, 2, 1],\n",
        "    thresholds=[5.0, 4.0, 3.0, 2.0],\n",
        "    a=a_, b=b_, c=c_, d=d_,\n",
        "    A_plus=0.01, A_minus=-0.008,\n",
        "    A_plus_r=0.01, A_minus_r=-0.008,\n",
        "    lb=0.2, ub=0.8,\n",
        "    reward_val=+1.0, punish_val=-1.0\n",
        ").to(device)\n",
        "\n",
        "# 5-Layer Model\n",
        "model_5layer = FlexibleDeepConvSNN(\n",
        "    in_channels=1,\n",
        "    layer_channels=[30, 60, 100, 150, 10],  # 5 layers\n",
        "    kernel_sizes=[5, 3, 3, 3, 3],\n",
        "    pool_sizes=[2, 2, 2, 2, 1],\n",
        "    pool_strides=[2, 2, 2, 2, 1],\n",
        "    thresholds=[5.0, 4.5, 4.0, 3.5, 3.0],\n",
        "    a=a_, b=b_, c=c_, d=d_,\n",
        "    A_plus=0.01, A_minus=-0.008,\n",
        "    A_plus_r=0.01, A_minus_r=-0.008,\n",
        "    lb=0.2, ub=0.8,\n",
        "    reward_val=+1.0, punish_val=-1.0\n",
        ").to(device)\n",
        "\n",
        "print(\"4-layer and 5-layer models created.\")\n",
        "\n",
        "# Training functions for the flexible models\n",
        "def train_flexible_model(model, train_loader, test_loader, num_layers):\n",
        "    \"\"\"\n",
        "    Train a flexible model with the specified number of layers\n",
        "    \"\"\"\n",
        "    print(f\"\\n=== Training {num_layers}-layer model ===\")\n",
        "\n",
        "    # Train each layer sequentially\n",
        "    for layer_idx in range(1, num_layers):\n",
        "        print(f\"=== Training layer {layer_idx} ===\")\n",
        "        train_layer(model, train_loader, layer_idx=layer_idx, epochs=2, max_images=500)\n",
        "\n",
        "        # Check intermediate accuracy\n",
        "        if layer_idx > 1:  # Only check after at least 2 layers are trained\n",
        "            acc = test_accuracy(model, test_loader)\n",
        "            print(f\"Accuracy after training layer {layer_idx}: {acc:.2f}%\")\n",
        "\n",
        "    # Train the final classification layer with R-STDP\n",
        "    print(f\"=== Training final layer (layer {num_layers}) with R-STDP ===\")\n",
        "\n",
        "    # Adapt the existing train_layer3_rstdp function for our flexible model\n",
        "    model.train()\n",
        "    for ep in range(2):  # 2 epochs\n",
        "        correct_during_training = 0\n",
        "        total_during_training = 0\n",
        "\n",
        "        for i, (data_spike_wave, target) in enumerate(train_loader):\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Processing image {i}...\")\n",
        "\n",
        "            data_spike_wave = data_spike_wave.to(device)\n",
        "            pot_final = model.forward_inference(data_spike_wave.squeeze(0))\n",
        "            pred_class_ = predict_class(pot_final)\n",
        "            lbl = target.item()\n",
        "\n",
        "            # Apply stronger reward/punishment based on correctness\n",
        "            reward_val = 1.5 if pred_class_ == lbl else -1.5\n",
        "\n",
        "            # Force activation of the correct class neuron\n",
        "            winners = [(lbl, 0, 0)]  # Always update the weights for the correct class\n",
        "            model.apply_r_stdp_direct(data_spike_wave.squeeze(0), pot_final, winners, reward_val)\n",
        "\n",
        "            # Track accuracy during training\n",
        "            if pred_class_ == lbl:\n",
        "                correct_during_training += 1\n",
        "            total_during_training += 1\n",
        "\n",
        "            if i % 100 == 99:\n",
        "                print(f\"Current training accuracy: {100*correct_during_training/total_during_training:.2f}%\")\n",
        "\n",
        "            if i >= 500-1:  # Limit to 500 images\n",
        "                print(f\"Reached maximum images (500), stopping training\")\n",
        "                break\n",
        "\n",
        "    # Apply mistake correction\n",
        "    print(\"=== Applying mistake correction ===\")\n",
        "    mistakes_fixed = train_on_mistakes(model, train_loader, max_mistakes=100)\n",
        "    print(f\"Trained on {mistakes_fixed} misclassified examples\")\n",
        "\n",
        "    # Final accuracy check\n",
        "    final_acc = test_accuracy(model, test_loader)\n",
        "    print(f\"Final {num_layers}-layer model accuracy: {final_acc:.2f}%\")\n",
        "\n",
        "    return model, final_acc\n",
        "\n",
        "# Train the 4-layer model\n",
        "model_4layer, acc_4layer = train_flexible_model(model_4layer, train_loader, test_loader, num_layers=4)\n",
        "\n",
        "# Train the 5-layer model\n",
        "model_5layer, acc_5layer = train_flexible_model(model_5layer, train_loader, test_loader, num_layers=5)\n",
        "\n",
        "# Compare results\n",
        "print(\"\\n=== Model Comparison ===\")\n",
        "print(f\"3-layer model accuracy: {best_accuracy:.2f}%\")\n",
        "print(f\"4-layer model accuracy: {acc_4layer:.2f}%\")\n",
        "print(f\"5-layer model accuracy: {acc_5layer:.2f}%\")"
      ],
      "metadata": {
        "id": "-iWsZUXgiFzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adaptive Training for Deeper Models"
      ],
      "metadata": {
        "id": "MjZx0q5DiOiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 14. Enhanced Prediction Function for Deeper Models\n",
        "\n",
        "def enhanced_predict_class(pot_final, confidence=False):\n",
        "    \"\"\"\n",
        "    Enhanced prediction function that works better with deeper models\n",
        "    Returns class prediction and optionally confidence scores\n",
        "    \"\"\"\n",
        "    T, C, H, W = pot_final.shape\n",
        "\n",
        "    # Calculate multiple metrics for each class\n",
        "    class_metrics = {\n",
        "        'spike_count': torch.zeros(C, device=pot_final.device),\n",
        "        'earliest_spike': torch.full((C,), T, device=pot_final.device),\n",
        "        'max_potential': torch.zeros(C, device=pot_final.device),\n",
        "        'spatial_spread': torch.zeros(C, device=pot_final.device)\n",
        "    }\n",
        "\n",
        "    # Calculate metrics for each class\n",
        "    for f in range(C):\n",
        "        channel_pot = pot_final[:, f]\n",
        "\n",
        "        # Spike count (total activations above threshold)\n",
        "        spike_mask = (channel_pot > 0).float()\n",
        "        class_metrics['spike_count'][f] = spike_mask.sum()\n",
        "\n",
        "        # Earliest spike time\n",
        "        for t in range(T):\n",
        "            if spike_mask[t].sum() > 0:\n",
        "                class_metrics['earliest_spike'][f] = t\n",
        "                break\n",
        "\n",
        "        # Maximum potential reached\n",
        "        class_metrics['max_potential'][f] = channel_pot.max()\n",
        "\n",
        "        # Spatial spread (how many spatial locations had spikes)\n",
        "        spatial_locations = torch.sum(spike_mask.view(T, -1) > 0, dim=1).float().sum()\n",
        "        class_metrics['spatial_spread'][f] = spatial_locations\n",
        "\n",
        "    # Combine metrics into a single score\n",
        "    # Earlier spikes, more spikes, higher potentials, and wider spread are better\n",
        "    combined_score = (\n",
        "        class_metrics['spike_count'] *\n",
        "        (T - class_metrics['earliest_spike']) *\n",
        "        class_metrics['max_potential'] *\n",
        "        (1 + 0.1 * class_metrics['spatial_spread'])\n",
        "    )\n",
        "\n",
        "    # Get prediction and confidence\n",
        "    pred_class = torch.argmax(combined_score).item()\n",
        "\n",
        "    if confidence:\n",
        "        # Calculate confidence as normalized score\n",
        "        confidence_score = F.softmax(combined_score, dim=0)\n",
        "        return pred_class, confidence_score\n",
        "    else:\n",
        "        return pred_class\n",
        "\n",
        "# Test the enhanced prediction function\n",
        "def test_with_enhanced_prediction(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data_spike_wave, target) in enumerate(loader):\n",
        "            data_spike_wave = data_spike_wave.to(device)\n",
        "            pot_final = model.forward_inference(data_spike_wave.squeeze(0))\n",
        "            pred_class_ = enhanced_predict_class(pot_final)\n",
        "            if pred_class_ == target.item():\n",
        "                correct += 1\n",
        "            total += 1\n",
        "    return 100.0 * correct / total\n",
        "\n",
        "# Compare prediction methods on all models\n",
        "print(\"\\n=== Comparing Prediction Methods ===\")\n",
        "print(\"Original prediction method:\")\n",
        "print(f\"3-layer model: {test_accuracy(model, test_loader):.2f}%\")\n",
        "print(f\"4-layer model: {test_accuracy(model_4layer, test_loader):.2f}%\")\n",
        "print(f\"5-layer model: {test_accuracy(model_5layer, test_loader):.2f}%\")\n",
        "\n",
        "print(\"\\nEnhanced prediction method:\")\n",
        "print(f\"3-layer model: {test_with_enhanced_prediction(model, test_loader):.2f}%\")\n",
        "print(f\"4-layer model: {test_with_enhanced_prediction(model_4layer, test_loader):.2f}%\")\n",
        "print(f\"5-layer model: {test_with_enhanced_prediction(model_5layer, test_loader):.2f}%\")"
      ],
      "metadata": {
        "id": "ZkZru0smiQnS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}